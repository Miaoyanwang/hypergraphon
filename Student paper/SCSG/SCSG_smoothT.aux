\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{baltrunas2011incarmusic}
\citation{Michoel2012AlignmentAI}
\citation{Agarwal2006HigherOL}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:int}{{1}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a): Illustration of order-$m$ $d$-dimensional permuted smooth tensor models with $m=2$. (b): Phase transition of mean squared error (MSE) (on $-\qopname  \relax o{log}d$ scale) as a function of smoothness $\alpha $ and tensor order $m$. Bold dots correspond to the critical smoothness level above which higher smoothness exhibits no further benefits to tensor estimation.\relax }}{1}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rate}{{1}{1}{(a): Illustration of order-$m$ $d$-dimensional permuted smooth tensor models with $m=2$. (b): Phase transition of mean squared error (MSE) (on $-\log d$ scale) as a function of smoothness $\alpha $ and tensor order $m$. Bold dots correspond to the critical smoothness level above which higher smoothness exhibits no further benefits to tensor estimation.\relax }{figure.caption.2}{}}
\newlabel{eq:rep}{{1}{1}{Introduction}{equation.1.1}{}}
\citation{gao2018minimax,klopp2017oracle}
\citation{shah2019low}
\citation{shah2020permutation}
\citation{balasubramanian2021nonparametric,li2019nearest}
\citation{gao2016optimal,klopp2017oracle,gao2018minimax}
\citation{wang2019multiway,han2020exact}
\MT@newlabel{eq:rep}
\MT@newlabel{eq:rep}
\@writefile{toc}{\contentsline {section}{\numberline {2}Smooth tensor model with unknown permutation}{2}{section.2}\protected@file@percent }
\newlabel{sec:md}{{2}{2}{Smooth tensor model with unknown permutation}{section.2}{}}
\MT@newlabel{eq:rep}
\newlabel{eq:defn}{{1}{2}{$\alpha $-H\"older smooth}{defn.1}{}}
\MT@newlabel{eq:rep}
\citation{wang2019multiway,han2020exact}
\@writefile{toc}{\contentsline {section}{\numberline {3}Block-wise tensor approximation }{3}{section.3}\protected@file@percent }
\newlabel{sec:tba}{{3}{3}{Block-wise tensor approximation}{section.3}{}}
\newlabel{eq:block}{{2}{3}{Block-wise tensor approximation}{equation.3.2}{}}
\MT@newlabel{eq:block}
\MT@newlabel{eq:rep}
\MT@newlabel{eq:rep}
\MT@newlabel{eq:block}
\newlabel{eq:blockind}{{3}{3}{Block-wise tensor approximation}{equation.3.2}{}}
\MT@newlabel{eq:rep}
\MT@newlabel{eq:block}
\@writefile{toc}{\contentsline {section}{\numberline {4}Fundamental limits via least-squares estimation}{3}{section.4}\protected@file@percent }
\newlabel{sec:lse}{{4}{3}{Fundamental limits via least-squares estimation}{section.4}{}}
\newlabel{eq:lseopt}{{3}{3}{Fundamental limits via least-squares estimation}{equation.4.3}{}}
\MT@newlabel{eq:lseopt}
\newlabel{thm:LSE}{{1}{3}{Least-squares estimation error}{thm.1}{}}
\MT@newlabel{eq:rep}
\MT@newlabel{eq:lseopt}
\newlabel{eq:rates}{{1}{3}{Least-squares estimation error}{thm.1}{}}
\citation{gao2016optimal,klopp2017oracle}
\citation{balasubramanian2021nonparametric}
\citation{balasubramanian2021nonparametric}
\citation{chan2014consistent}
\citation{han2019isotonic,pananjady2020isotonic}
\newlabel{thm:minimax}{{2}{4}{Minimax lower bound}{thm.2}{}}
\MT@newlabel{eq:rep}
\newlabel{eq:minimax}{{2}{4}{Minimax lower bound}{thm.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}An adaptive and computationally feasible procedure}{4}{section.5}\protected@file@percent }
\newlabel{sec:borda}{{5}{4}{An adaptive and computationally feasible procedure}{section.5}{}}
\MT@newlabel{eq:lseopt}
\MT@newlabel{eq:lseopt}
\newlabel{eq:defn}{{2}{4}{$\beta $-monotonicity}{defn.2}{}}
\newlabel{eq:monotonic}{{2}{4}{$\beta $-monotonicity}{defn.2}{}}
\MT@newlabel{eq:lseopt}
\newlabel{thm:BC}{{3}{4}{Estimation error for Borda count}{thm.3}{}}
\MT@newlabel{eq:rep}
\newlabel{eq:BC}{{3}{4}{Estimation error for Borda count}{thm.3}{}}
\citation{xu2018rates}
\citation{balasubramanian2021nonparametric}
\citation{Jeremy.2020}
\citation{Jeremy.2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Procedure of Borda count estimation. We first sort the tensor entries using the proposed procedure. Then, we estimate the signal tensor using block-$k$ degree-$\ell $ polynomial approximation.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:borda}{{2}{5}{Procedure of Borda count estimation. We first sort the tensor entries using the proposed procedure. Then, we estimate the signal tensor using block-$k$ degree-$\ell $ polynomial approximation.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Numerical experiments and data application}{5}{section.6}\protected@file@percent }
\newlabel{sec:sim}{{6}{5}{Numerical experiments and data application}{section.6}{}}
\MT@newlabel{eq:rep}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Panels a-c: MSE comparison versus the number of blocks for different polynomial approximation under models 1-3 respectively. Panel d-f: MSE comparison of different methods versus tensor dimension under models 1-3 respectively. MSEs are measured across $n_{\text  {sim}} = 20$ replications.\relax }}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:degk}{{3}{5}{Panels a-c: MSE comparison versus the number of blocks for different polynomial approximation under models 1-3 respectively. Panel d-f: MSE comparison of different methods versus tensor dimension under models 1-3 respectively. MSEs are measured across $n_{\text {sim}} = 20$ replications.\relax }{figure.caption.4}{}}
\MT@newlabel{eq:lseopt}
\bibstyle{plain}
\bibdata{tensor_wang}
\bibcite{Agarwal2006HigherOL}{{1}{}{{}}{{}}}
\bibcite{balasubramanian2021nonparametric}{{2}{}{{}}{{}}}
\bibcite{baltrunas2011incarmusic}{{3}{}{{}}{{}}}
\bibcite{chan2014consistent}{{4}{}{{}}{{}}}
\bibcite{gao2016optimal}{{5}{}{{}}{{}}}
\bibcite{gao2018minimax}{{6}{}{{}}{{}}}
\bibcite{han2019isotonic}{{7}{}{{}}{{}}}
\bibcite{han2020exact}{{8}{}{{}}{{}}}
\bibcite{Jeremy.2020}{{9}{}{{}}{{}}}
\bibcite{klopp2017oracle}{{10}{}{{}}{{}}}
\bibcite{li2019nearest}{{11}{}{{}}{{}}}
\bibcite{Michoel2012AlignmentAI}{{12}{}{{}}{{}}}
\bibcite{pananjady2020isotonic}{{13}{}{{}}{{}}}
\bibcite{shah2019low}{{14}{}{{}}{{}}}
\bibcite{shah2020permutation}{{15}{}{{}}{{}}}
\bibcite{wang2019multiway}{{16}{}{{}}{{}}}
\bibcite{xu2018rates}{{17}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Panel a: smooth functions in simulations. Panels b-c: Chicago crime maps. Panel b shows homicides and shooting incidents in community areas in Chicago. This figure is from \textit  {Chicago Tribune} article in 2020 \citep  {Jeremy.2020}. Panel c shows the four areas estimated by our Borda Count algorithm. \relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:area}{{4}{6}{Panel a: smooth functions in simulations. Panels b-c: Chicago crime maps. Panel b shows homicides and shooting incidents in community areas in Chicago. This figure is from \textit {Chicago Tribune} article in 2020 \citep {Jeremy.2020}. Panel c shows the four areas estimated by our Borda Count algorithm. \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{6}{section.7}\protected@file@percent }
\newlabel{sec:con}{{7}{6}{Conclusion}{section.7}{}}
