\documentclass{article}
\usepackage{enumitem}
\usepackage{lipsum}
\input{UWletterdefs}
\usepackage{ragged2e}
\justifying
\usepackage{amsmath,amssymb}

\begin{document}
Please consider our article titled ``Smooth tensor estimation with unknown permutations'' for publication in Journal of the American Statistical Association (Theory and Methods). 

Higher-order tensors have recently attracted increased attention across science and engineering. In this article, we consider the problem of structured tensor denoising in the presence of unknown permutations. Such data problems arise commonly in recommendation system, neuroimaging, and multiway comparison applications. We develop a general family of permuted smooth tensor models up to arbitrary index permutations; the model incorporates the popular tensor block models and Lipschitz hypergraphon models as special cases.  We show that a constrained least-squares estimator in the block-wise polynomial family achieves the minimax error bound. A phase transition phenomenon is revealed with respect to the smoothness threshold needed for optimal recovery. In particular, we find that a polynomial of degree up to $(m -2)(m + 1)/2$ is sufficient for accurate recovery of order-$m$ tensors, whereas higher degree exhibits no further benefits. This phenomenon reveals the intrinsic distinction for smooth tensor estimation problems with and without unknown permutations. Furthermore, we provide an efficient polynomial-time Borda count algorithm that provably achieves optimal rate under monotonicity assumptions. The efficacy of our procedure is demonstrated through simulations and Chicago crime data analysis.


We believe our results will be of interest to a very broad readership -- from those interested in theoretical foundations of tensor methods to those in tensor data applications. Our method will help the practitioners efficiently analyze tensor datasets in various areas. Toward this end, the software package and all data used have been publicly released at CRAN. 

Suitable associate editors for our work include: Lexin Li (University of California, Berkeley; Tensor analysis), Annie Qu (University of California Irvine; Statistical learning), and Guang Cheng (Purdue University; Statistical learning).

Thank you very much for your consideration.

\end{document}
